{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center><u>Twitter Sentiment</u></center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> This notebook takes a training csv file and creates a model based on positive or negative sentiment, which is then tested against a testing csv file using the saved model. </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, Conv1D, MaxPooling1D, SpatialDropout1D, Flatten\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import re\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Clean the Data\n",
    "Load the data as before with pandas and take a look at the data so we know what we will be working with. \n",
    "\n",
    "To Do:\n",
    "- Load the dataset into a dataframe with pandas\n",
    "- Clean the data so it is easier to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>is so sad for my APL frie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>I missed the New Moon trail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>omg its already 7:30 :O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>i think mi bf is cheating on me!!!   ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Sentiment                                      SentimentText\n",
       "0   1          0                       is so sad for my APL frie...\n",
       "1   2          0                     I missed the New Moon trail...\n",
       "2   3          1                            omg its already 7:30 :O\n",
       "3   4          0            .. Omgaga. Im sooo  im gunna CRy. I'...\n",
       "4   5          0           i think mi bf is cheating on me!!!   ..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.read_csv('train_kaggle.csv', encoding = \"ISO-8859-1\")\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     is so sad for my apl friend\n"
     ]
    }
   ],
   "source": [
    "tweets['SentimentText'] = tweets['SentimentText'].apply(lambda x : re.sub('[^a-zA-Z0-9\\s]', '', x.lower()))\n",
    "print(tweets['SentimentText'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenise\n",
    "We are going to use tokenisation to find the 2000 most common words. Tokenising is used on a sequence of words (basically a sentence) to count their frequency. A *token* is an instance of a sequence of characters (basically a word). A type is the class of all tokens containing the same character sequence.\n",
    "\n",
    "To Do:\n",
    "- Define the max features\n",
    "- Initialise a tokeniser with the max feature and a defined split\n",
    "- Calculate the different word frequencies \n",
    "- Add padding to the sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vect = CountVectorizer()\n",
    "x = vect.fit_transform(tweets['SentimentText'])\n",
    "print(x.toarray())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Model \n",
    "As before define and build the model you want to train with this dataset. \n",
    "\n",
    "To Do:\n",
    "- Define a sequential model and add your layers. \n",
    "- Compile the model\n",
    "- (Optional) Display the layers with summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eoinmcmahon/Library/Python/2.7/lib/python/site-packages/ipykernel_launcher.py:6: UserWarning: The `dropout` argument is no longer support in `Embedding`. You can apply a `keras.layers.SpatialDropout1D` layer right after the `Embedding` layer to get the same behavior.\n",
      "  \n",
      "/Users/eoinmcmahon/Library/Python/2.7/lib/python/site-packages/ipykernel_launcher.py:7: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(200, dropout=0.2, recurrent_dropout=0.2)`\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 89252, 128)        320000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 200)               263200    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 402       \n",
      "=================================================================\n",
      "Total params: 583,602\n",
      "Trainable params: 583,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embedding_dimensions = 128\n",
    "lstm_out = 200 \n",
    "batch_size = 32\n",
    "#custom_adam = keras.optimizers.Adam(lr=0.005, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n",
    "model = Sequential()\n",
    "model.add(Embedding(2500, embedding_dimensions,input_length = x.shape[1], dropout = 0.2))\n",
    "model.add(LSTM(lstm_out, dropout_U = 0.2, dropout_W = 0.2))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "print(model.summary())\n",
    "#print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210000\n"
     ]
    }
   ],
   "source": [
    "print(tweets.size)\n",
    "y = pd.get_dummies(tweets['Sentiment']).values\n",
    "batch_size = 406\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size = 0.3, random_state = 1234)\n",
    "#print(X_train.shape,Y_train.shape)\n",
    "#print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyStopping=keras.callbacks.EarlyStopping(monitor='val_acc', min_delta = 0.1, patience=0, verbose=2, mode='auto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 49000 samples, validate on 21000 samples\n",
      "Epoch 1/20\n"
     ]
    }
   ],
   "source": [
    "# works well at epochs: 5,7, \n",
    "\n",
    "model.fit(X_train, Y_train, epochs=20, batch_size = batch_size, validation_data=(X_test, Y_test), shuffle=True, callbacks=[earlyStopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTING\n",
    "\n",
    "model 0 --> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.49\n",
      "acc: 0.76\n"
     ]
    }
   ],
   "source": [
    "validation_size = 1500\n",
    "X_validate = X_test[-validation_size:]\n",
    "Y_validate = Y_test[-validation_size:]\n",
    "X_test = X_test[:-validation_size]\n",
    "Y_test = Y_test[:-validation_size]\n",
    "score,acc = model.evaluate(X_test, Y_test, verbose = 2, batch_size = batch_size)\n",
    "print(\"score: %.2f\" % (score))\n",
    "print(\"acc: %.2f\" % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"bens_tweet_model.hdf5\")\n",
    "model = load_model(\"bens_tweet_model.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test_data_kaggle.csv', encoding = \"ISO-8859-1\")\n",
    "test.head()\n",
    "test['SentimentText'] = test['SentimentText'].apply(lambda x : re.sub('[^a-zA-Z0-9\\s]', '', x.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n"
     ]
    }
   ],
   "source": [
    "max_features = 2000\n",
    "tokeniser = Tokenizer(num_words=max_features, split=' ')\n",
    "tokeniser.fit_on_texts(test['SentimentText'].values)\n",
    "x = tokeniser.texts_to_sequences(test['SentimentText'].values)\n",
    "x = pad_sequences(x, maxlen=84)\n",
    "print (len(x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Id': 0         70013\n",
      "1         70014\n",
      "2         70015\n",
      "3         70016\n",
      "4         70017\n",
      "5         70018\n",
      "6         70019\n",
      "7         70020\n",
      "8         70021\n",
      "9         70022\n",
      "10        70023\n",
      "11        70024\n",
      "12        70025\n",
      "13        70026\n",
      "14        70027\n",
      "15        70028\n",
      "16        70029\n",
      "17        70030\n",
      "18        70031\n",
      "19        70032\n",
      "20        70033\n",
      "21        70034\n",
      "22        70035\n",
      "23        70036\n",
      "24        70037\n",
      "25        70038\n",
      "26        70039\n",
      "27        70040\n",
      "28        70041\n",
      "29        70042\n",
      "          ...  \n",
      "29958     99971\n",
      "29959     99972\n",
      "29960     99973\n",
      "29961     99974\n",
      "29962     99975\n",
      "29963     99976\n",
      "29964     99977\n",
      "29965     99978\n",
      "29966     99979\n",
      "29967     99980\n",
      "29968     99981\n",
      "29969     99982\n",
      "29970     99983\n",
      "29971     99984\n",
      "29972     99985\n",
      "29973     99986\n",
      "29974     99987\n",
      "29975     99988\n",
      "29976     99989\n",
      "29977     99990\n",
      "29978     99991\n",
      "29979     99992\n",
      "29980     99993\n",
      "29981     99994\n",
      "29982     99995\n",
      "29983     99996\n",
      "29984     99997\n",
      "29985     99998\n",
      "29986     99999\n",
      "29987    100000\n",
      "Name: Id, Length: 29988, dtype: int64, 'Sentiment': array([1, 1, 1, ..., 0, 0, 1])}\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_classes(x)\n",
    "data = {'Id' : test['Id'], 'Sentiment' : predictions}\n",
    "print (data)\n",
    "df = pd.DataFrame(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70013</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id  Sentiment\n",
       "0  70013          1\n",
       "1  70014          1\n",
       "2  70015          1\n",
       "3  70016          1\n",
       "4  70017          1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype(str)\n",
    "df.to_csv('new_output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id           object\n",
       "Sentiment    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
